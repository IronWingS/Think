```xml
连接数据库，
<db_ip>192.168.48.100</db_ip>
<db_name>homed_dtvs</db_name>
<db_username>homed</db_username>
<db_password>newclustersql</db_password>
```



```shell
mysql -h 192.168.48.100 -P 3306 -u homed -p newclustersql
```





# 2020-11-27

- [x] 今天的主要工作就是完成两种不同格式数据的统一，并让他们进行运算。

- [x] 然后有时间就搞定docker跨主机通信的问题。（问了下，结果这个需要用docker compose来做，就很麻烦了，今天搞不定，只能先有个大概了解）
- [ ] 刷算法，今天任务少，其实可以偷偷多刷几道



统一时间格式这个，mysql没问题。但是DataFrame，我最开始是想找一个类似的api，但是昨天一下午都没找到。今天，还是先找找看，如果有现成的方法，就直接用吧。

如果还是没找到，就看能不能把s换成datatype。

总之就是要求两个数的商。



# 2020-11-30

今天主要是要搞好docker的一键化部署的脚本还有文档，因为文档的一些内容有些变动，然后就是把文档再改一版为部署的步骤说明性文档，就不要那种科普性的了。

然后上周五本来说多刷几道算法，结果一到也没刷，今天必须至少刷一道算法题。

还有公众号，现在是148个粉丝， 哎，都是我爸妈的功劳，我也得支棱起来啊。今天无论如何得发一篇文章。

- [x] 搞定docker一键部署代码
- [x] 整理两份docker文档
- [ ] 一道算法题
- [ ] 一篇公众号文章

**注意，这不是演习，今天必须全部做完，绝对不能留尾巴！！！**



# 2020-12-2

女朋友并不能帮我解决现在遇到的问题；一个名校学历并不能帮我解决我现在遇到的问题；名牌公司也不能帮我解决现在遇到的问题。

只能靠自己。

- [x] 搞定如何使用spark读取hive数据
- [ ] 解决算法“遍历二叉树的神级方法”
- [x] 编写代码“如何直观的打印二叉树”
- [x] 完成公众号文章“基于docker搭建大数据平台系列（一）”
- [x] 健身，今天炼背
- [x] 解决linux长命令不能换行的问题，vim只显示一半的问题

任务完成率  **83.3 %**

# 2020-12-3

- [x] 搞定hive读数据异常的问题
- [x]  把工作环境迁移到mac上
- [ ] 搞定算法“遍历二叉树的神级方法”
- [x] 发表公众号文章“基于docker搭建大数据平台系列（一）”
- [ ] 整理公众号文章的大纲
- [ ] 复习“如何直观的打印二叉树”的算法

任务完成率： **50%**



# 2020-12-4

- [x] 分析hive中的数据，是否有异常
- [x] 搞定所有的开发任务
- [ ] 搞定算法“遍历二叉树的神级方法”
- [ ] 整理公众号文章的大纲
- [ ] 复习“如何直观的打印二叉树”的算法
- [ ] 任务完成率要比昨天高



# 2020-12-14

目前遇到的这个任务，第一个难点，就是怎么把DataFrame保存到HBase中，关键是，这个DataFrame中有一列是不断变化的，所以相应的HBase中的列族也要变幻，也就是要实现动态插入DataFrame的列。

- [ ]  安装好伪分布模式的HBase
- [ ] 搞定HBase如何在列族中新增一列
- [ ] DataFrame怎么把一列按 | 进行分割
- [ ] 算法
- [ ] 公众号文章



# 2020-12-17

虽然有很多槽点，吐槽就行了，狠狠的吐槽，然后好好的学知识，不要忘了来这家公司的初心。

- [ ] 最多只在HBase中每个RowKey只保存30条的数据，这个感觉是可以通过程序来实现，因为可以通过scala代码实现HBase表的删除功能。

  就是，先利用程序读取每个rowkey对应的数据，统计一下数据量的大小，如果超过30条，就把这些数据全部删掉，重新开始写。

  那如果用phoenix来做这个事情，怎么样。就是对数据的增和删。（这个后面肯定还是得搞，暂时先放一放。）

  然后另一个列族的话，其实就可以不做处理，因为是统计的值，那么就可以保持现有的列结构，是要把总计的值加起来就可以



| rowkey  | colfamily 1（保存30天的数据）            | colfamily 2 (另一个列族的求和值)       |
| ------- | ---------------------------------------- | -------------------------------------- |
|         | col1 \| col 2 \|  col 3  (series_id ...) | col 1 \| col 2 \| col 3 (series_id...) |
| user_id |                                          |                                        |



- 把每天的增量信息保存到cf1中，
  - 统计当前rowkey的数据条数，如果不超过30条，直接写入
  - 如果超过30条，删除多该rowkey对应的所有数据，再写入
- 把增量信息加到cf2中
  - cf2的表中只做添加和更新操作，不作删除。



**HBase的随机读写是什么意思？得搞清楚**



那今天的工作内容就是：

- [x] 设置好表结构
- [x] 把DataFrame写入到Hbase表中
- [ ] 读取RowKey对应的数据条数
- [ ] 删除RowKey对应第一个列族的数据









